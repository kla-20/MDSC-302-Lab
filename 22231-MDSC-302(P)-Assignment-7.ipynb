{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77d051a",
   "metadata": {},
   "source": [
    "##### Name: K Lalith Aditya\n",
    "##### Regd No: 22231\n",
    "##### SAVE AND LOAD THE MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b3801",
   "metadata": {},
   "source": [
    "persist model state with saving, loading, running model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac24e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6298856b",
   "metadata": {},
   "source": [
    "#### Saving and loading model weights\n",
    "Pytorch models store the learned parameters in an internal state dictionary, called state_dict. These can be done by torch.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b87c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "# creates a vgg16 model and the pre_trained weights will be of the IMAGENET1K_V1 dataset\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "# saves the model state into a file called model_weights.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d00258",
   "metadata": {},
   "source": [
    "To load the model_weights, instance of the same model must be created. The parameters should be loaded with load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83e6de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # loading the vgg16 model\n",
    "model.load_state_dict(torch.load('model_weights.pth')) # loading the state(model weights) into the model\n",
    "model.eval() # setting the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c866d",
   "metadata": {},
   "source": [
    "#### Saving and Loading Models with Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169a697",
   "metadata": {},
   "source": [
    "when loading the model weights we needed to instantiate the model class first, because the class defines the structure of a network. We want to save the structure of this class together with the model. In this case we will pass the model (not model.state_dict()) to the saving function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd80bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth') # saving model state into model from the model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4619109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model \n",
    "model = torch.load('model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
